排序算法的关键指标

时空复杂度 时间复杂度和空间复杂度 
排序稳定性 

对于序列中的相同元素 如果排序之后它们的相对位置没有发生改变 则称之为稳定排序 反之为不稳定排序 

是否原地排序 
原地排序就是指排序过程中不需要额外的辅助空间 只需要常数级别的额外空间 直接操作原数组进行排序 

注意，关键是是否需要额外的空间，而不是是否返回一个新的数组。具体来说就是类似这样的区别：

// 非原地排序
void sort(int[] nums) {
    // 排序过程中需要额外的辅助数组，消耗 O(N) 的空间
    int[] tmp = new int[nums.length];

    // 对 nums 进行排序
    for ...
}

// 原地排序
void sort(int[] nums) {
    // 直接操作 nums，不需要额外的辅助数组，消耗 O(1) 的空间
    for ...
}

选择排序 
先遍历一遍数组，找到数组中的最小值，然后把它和数组的第一个元素交换位置；接着再遍历一遍数组，找到第二小的元素，和数组的第二个元素交换位置；以此类推，直到整个数组有序。

这个算法有一个被大家熟知的名字，叫做「选择排序」，即每次都去遍历选择最小的元素。写成代码就是这样的：

void sort(int [] nums){
    int n= nums.length;
    int sortedIndex = 0;
    while(sortedIndex<n){
      int minIndex = sortedIndex;
      for(int i = sortedIndex+1;i<n;i++){
          if(nums[i]<nums[minIndex]){
            minIndex = i;
          }
      }
      int temp = nums[sortedIndex];
      nums[sortedIndex] = nums[minIndex];
      nums[minIndex] = temp;

      sortedIndex++;
    }
}


冒泡排序 
算是选择排序的一种优化 通过交换 nums[sortedIndex] 右侧的逆序对完成排序 
是一种稳定排序算法


void sort（int[] nums）{
    int n = nums.length;
    int sortedIndex = 0;
    while(sortedIndex < n){
        boolean swapped = false;
        for(int i = n-1 ; i>sortedIndex;i--){
        if(nums[i]<nums[i-1]){
          int tmp = nums[i];
          nums[i] = nums[i-1];
          nums[i-1] = tmp;
          swapped = true;
          
        }
        }
        if(!swapped){
        break;
        }
        sortedIndex++;
    }
}

还是o（n^2）并没有降低

插入排序是基于选择排序的一种优化 将nums[sortedIndex]插入到左侧的有序数组中，对有序度较高的数组 ，插入排序的效率比较高 

对选择排序进行进一步优化 向左侧有序数组中插入元素 
这个算法有另一个名字 就是插入排序 

void sort（int [] nums）{
    int n = nums.length;
    int sortedIndex = 0;
    //维护[0,sortedIndex)是有序数组 
    while(sortedIndex < n){
        for(int i = sortedIndex;i>0;i--){
        if(nums[i]<nums[i-1]){
            int tmp= num[i];
            nums[i] = nums[i-1];
            nums[i-1] = tmp;
        }else{
        break;
        }
        }
        sortedIndex++;
    }
}

显然，插入排序的效率和输入数组的有序度有很大关系，可以举极端例子来理解：

如果输入数组已经有序，或者仅有个别元素逆序，那么插入排序的内层 for 循环几乎不需要执行元素交换，所以时间复杂度接近 
O
(
n
)
O(n)。

如果输入的数组是完全逆序的，那么插入排序的效率就会很低，内层 for 循环每次都要对 nums[0..sortedIndex-1] 的所有元素进行交换，算法的总时间复杂度就接近 
O
(
n
2
)
O(n 
2
 )。

如果对比插入排序和冒泡排序，插入排序的综合性能应该要高于冒泡排序。

直观地说，插入排序的内层 for 循环，只需要对 sortedIndex 左侧 nums[0..sortedIndex-1] 这部分有序数组进行遍历和元素交换，大部分非极端情况下，可能不需要遍历完 nums[0..sortedIndex-1] 的所有元素；而冒泡排序的内层 for 循环，每次都需要遍历sortedIndex 右侧 nums[sortedIndex..] 的所有元素。

所以冒泡排序的操作数大约是 
n
2
/
2
n 
2
 /2，而插入排序的操作数会小于 
n
2
/
2
n 
2
 /2。

你可以把插入排序的代码拿去力扣第 912 题「排序数组」提交，它最终依然会超时，但可以说明算法代码的逻辑是正确的。之后的文章我们继续探讨如何对排序算法进行优化。


希尔排序 希尔排序是基于插入排序的简单改进 通过预处理增加数组的局部有序性 突破了插入排序的o（n2）

必须承认，希尔排序的思路很难想到，我是在《算法 4》第一次了解到这个算法，然后惊叹于这个算法的简单优化竟然能给插入排序带来如此大的提升。

首先我们要明确一个 h 有序数组 的概念。
一个数组是 h 有序的，是指这个数组中任意间隔为 h（或者说间隔元素的个数为 h-1）的元素都是有序的。


希尔排序
我在前文 
插入排序 分析过，插入排序对于有序度较高的数组效率很高，直逼 
O
(
n
)
O(n)，但对于有序度低（元素分布较随机）的数组就只有 
O
(
n
2
)
O(n 
2
 ) 了。

是否可以优化插入排序，使得即便有序度很低时，其时间复杂度也低于 
O
(
n
2
)
O(n 
2
 ) 呢？

希尔排序要发表看法了

你插入排序的问题是，上来就想着一步到位，直接把乱序数组变成 1 有序数组。而我希尔排序不着急，比方说，我先把乱序数组变成一个 16 有序数组，然后再变成 8 有序数组，4 有序数组，2 有序数组，最后变成 1 有序数组，完成排序。

这个 1, 2, 4, 8, 16... 的序列称之为「递增函数」，我上面举的例子的递增函数就是 
2
k
−
1
2 
k−1
 。

那么如何把一个数组变成 h 有序数组呢？基于插入排序的代码改动几个地方就行了，直接看希尔排序的代码吧：

void sort(int[] nums){
        int n = nums.length;
        //我们使用的生成函数是2的k-1次方即h = 1 2 4 8 16 
        int h = 1;
        while (h<n/2){
                h = 2*h;
        } 
        while(h>1){
            int sortedIndex = h;
            while(sortedIndex < n ){
                for(int i = sortedIndex ; i> h;i -=h){
                    if(nums[i]<nums[i-h]){
                        int tmp = nums[i];
                        nums[i] = nums[i-h];
                        nums[i-h] = tmp;
                }else{
                    break;
                }
            }
                sortedIndex ++;
        }
        h/=2;
}
递增函数的选择是关键

希尔排序的性能和递增函数的选择有很大关系，上面的代码中我们使用的递增函数是 
2
k
−
1
2 
k−1
 ，因为这是最简单的，但这并不最优的选择。


比方说《算法 4》 中给的递增函数是 
(
3
k
−
1
)
/
2
(3 
k
 −1)/2，即 
1
,
4
,
13
,
40
,
121
,
364...
1,4,13,40,121,364...，代码如下，主要修改 h 的初始化和更新逻辑：
void sort(int[] nums) {
    int n = nums.length;
    // 把生成函数换成 (3^k - 1) / 2
    // 即 h = 1, 4, 13, 40, 121, 364...
    int h = 1;
    while (h < n / 3) {
        h = 3 * h + 1;
    }

    while (h >= 1) {
        int sortedIndex = h;
        while (sortedIndex < n) {
            for (int i = sortedIndex; i >= h; i -= h) {
                if (nums[i] < nums[i - h]) {
                    int tmp = nums[i];
                    nums[i] = nums[i - h];
                    nums[i - h] = tmp;
                } else {
                    break;
                }
            }
            sortedIndex++;
        }

        // 按照递增函数的规则，缩小 h
        h /= 3;
    }
}

排序稳定性
希尔排序是不稳定排序。

这个比较容易理解吧，当 h 大于 1 时进行的排序操作，就可能打乱相同元素的相对位置了。
时空复杂度分析
希尔排序的空间复杂度是 
O
(
1
)
O(1)，是原地排序算法。

希尔排序的时间复杂度很难分析，主要取决于递增函数的选择，且涉及较多的数学知识，这里就不展开了，不过一个重要结论是：希尔排序的时间复杂度是小于 
O
(
N
2
)
O(N 
2
 ) 的。

这一点可以直观感受出来，毕竟前面的 
选择排序、
冒泡排序 和 
插入排序 都过不了第 912 题的所有用例，而希尔排序可以。

建议把 
(
3
k
−
1
)
/
2
(3 
k
 −1)/2 作为递增函数来写希尔排序的代码，这种写法的效率相对较高。

好了，绕了一大圈，终于能够成功通过第 912 题「排序数组」了，有没有感觉到一些小激动？

从希尔排序开始，复杂度为 
O
(
n
2
)
O(n 
2
 ) 的初级排序算法就告一段落了，接下来的高级排序算法一个比一个能打，当然，也很难通过你自己独立推导出来了。



下面是快速排序 

妙用二叉树的前序位置 快速排序 

快速排序的核心思路要结合二叉树的前序遍历来理解 在二叉树遍历的前序位置将一个元素排好位置 然后递归将剩下的元素拍好位置 
越是效率高的算法 离计算思维越近 未经训练的人越难理解 

快速排序的核心思路  
1.在nums数组中 任意选择一个元素 作为切分元素 pivot 一般选择第一个元素 
2.对数组中的元素进行若干交换操作 将小于pivot的元素放在左边 大于pivot的元素放在后面 其实就是将pivot这个元素排好序 
3.递归的对pivot左边的元素和右边的数组重复上述步骤 寻找新的切分元素 交换元素 使得切分元素左侧的元素都比它大 其实就是递归的把pivot左右两侧的元素排好序 

4、递归的重复上述操作 
所以我说快速排序的思路是：先把一个元素排好序，然后去把剩下的元素排好序。

代码框架 

void sort（int [] nums , int lo , int hi）{
        if(lo>hi){
        return ;
        }
    // 对 nums[lo..hi] 进行切分，将 nums[p] 排好序
    // 使得 nums[lo..p-1] <= nums[p] < nums[p+1..hi]
        int p = partition(nums,lo,hi);
sort(nums,lo,p-1);
sort(nums,p+1.hi);
}
其中 partition 函数的实现是快速排序的核心，即遍历 nums[lo..hi]，将切分点元素 pivot 放到正确的位置，并返回该位置的索引 p。

如果你还有印象的话，这个代码框架就是 
二叉树遍历基础 里的前序遍历框架，所以我说快速排序的本质是二叉树的前序遍历，在前序位置将 nums[p] 排好序，然后递归排序左右元素：

理想情况这棵树是平衡二叉树，即树高是 
O
(
log
⁡
n
)
O(logn)，所以总的时间复杂度是 
O
(
n
log
⁡
n
)
O(nlogn)，即树高乘以每层的复杂度。

空间复杂度
快速排序不需要额外的辅助空间，是原地排序算法。

递归遍历二叉树时，递归函数的堆栈深度为树的高度，所以空间复杂度是 
O
(
log
⁡
n
)
O(logn)。

稳定性
快速排序是不稳定排序算法，因为在 partition 函数中，不会考虑相同元素的相对位置，所以相同元素的相对位置可能会发生变化。

妙用二叉树的后序位置 归并排序 

一句话总结 归并排序的核心思路需要结合二叉树的后序遍历来理解 先利用递归把左右两半子数组排好序 然后在二叉树的后序位置合并两个有序数组 
归并排序的核心思路
本文归并排序的思路是，把数组切成两半，先把这两半子数组分别排好序，然后再合并这两个有序数组，整个数组就排好序了。
void sort(int [] nums , int lo ,int hi){
        if(lo == hi ){
            return;
        }
        int mid = （lo + hi）/2;
        sort(nums,lo,mid+1);
        sort(nums,mid+1,hi);
        merge(nums,lo,mid,hi);
}

排序稳定性 取决于merge函数的实现 需要双指针技巧 归并排序是稳定排序 
时间复杂度
每向下一层，每个节点的数组元素就减半，但是每一层总的元素数量就是数组的长度 
O
(
n
)
O(n)。

这棵二叉树是平衡二叉树，即树高是 
O
(
log
⁡
n
)
O(logn)，所以总的时间复杂度是 
O
(
n
log
⁡
n
)
O(nlogn)，即树高乘以每层的复杂度。

是否是原地排序？
不是原地排序。归并排序的 merge 函数需要一个额外的数组来辅助进行有序数组的合并操作，消耗 
O
(
n
)
O(n) 的空间。

二叉堆的运用 堆排序 
堆排序是从 
二叉堆结构 衍生出来的排序算法，复杂度为 
O
(
N
log
⁡
N
)
O(NlogN)。堆排序主要分两步，第一步是在待排序数组上原地创建二叉堆（Heapify），然后进行原地排序（Sort）。

、二叉堆（优先级队列）底层是用数组实现的，但是逻辑上是一棵完全二叉树，主要依靠 swim, sink 方法来维护堆的性质。

2、优先级队列可以分为小顶堆和大顶堆，小顶堆会将整个堆中最小的元素维护在堆顶，大顶堆会将整个堆中最大的元素维护在堆顶。

3、优先级队列插入元素时，首先把元素追加到二叉堆底部，然后调用 swim 方法把该元素上浮到合适的位置，时间复杂度是 
O
(
log
⁡
N
)
O(logN)。

4、优先级队列删除堆顶元素时，首先把堆底的最后一个元素交换到堆顶作为新的堆顶元素，然后调用 sink 方法把这个新的堆顶元素下沉到合适的位置，时间复杂度是 
O
(
log
⁡
N
)
O(logN)。

那么最简单的堆排序算法思路就是直接利用优先级队列，把所有元素塞到优先级队列里面，然后再取出来，不就完成排序了吗？
// 直接利用优先级队列对数组从小到大排序
void sort(int[] nums) {
    // 创建一个从小到大排序元素的小顶堆
    SimpleMinPQ pq = new SimpleMinPQ(nums.length);
    // 先把所有元素插入到优先级队列中
    for (int num : nums) {
        // push 操作会自动构建二叉堆，时间复杂度为 O(logN)
        pq.push(num);
    }
    // 再把所有元素取出来，就是从小到大排序的结果
    for (int i = 0; i < nums.length; i++) {
        // pop 操作从堆顶弹出二叉堆堆中最小的元素，时间复杂度为 O(logN)
        nums[i] = pq.pop();
    }
}

所以，堆排序要解决的问题是，不要使用额外的辅助空间，直接在原数组上进行 sink, swim 操作，在 
O
(
N
log
⁡
N
)
O(NlogN) 的时间内完成排序。

堆排序的两个关键步骤

1、原地建堆（Heapify）：直接把待排序数组原地变成一个二叉堆。

2、排序（Sort）：将元素不断地从堆中取出，最终得到有序的结果。


void sort(int[] nums){
       // 第一步，原地建堆，注意这里创建的是大顶堆
       // 只要从左往右对每个元素调用 swim 方法，就可以原地建堆
        for(int i = 0 ; i<nums.length ;i++){
            maxHeapSwim(nums,i);
        }
        int heapSize = nums.length;
        while(heapSize>0){
            swap(nums,0,heapSize - 1);
            heapSize--;
            maxHeapSink(nums,0,heapSize);
        }
}

// 大顶堆的下沉操作
void maxHeapSink(int[] heap, int node, int size) {
    while (left(node) < size || right(node) < size) {
        // 小顶堆和大顶堆的唯一区别就在这里，比较逻辑相反
        // 比较自己和左右子节点，看看谁最大
        int max = node;
        if (left(node) < size && heap[left(node)] > heap[max]) {
            max = left(node);
        }
        if (right(node) < size && heap[right(node)] > heap[max]) {
            max = right(node);
        }
        if (max == node) {
            break;
        }
        swap(heap, node, max);
        node = max;
    }
}


// 大顶堆的上浮操作
void maxHeapSwim(int[] heap, int node) {
    while (node > 0 && heap[parent(node)] < heap[node]) {
        swap(heap, parent(node), node);
        node = parent(node);
    }
}

这里面一个关键点是要用大顶堆来完成 nums 从小到大的排序，因为从堆顶删除的元素是从后往前填到 nums 数组中的，最终 nums 中的元素是从小到大排序的。

如果你用小顶堆的话，最终 nums 中的元素是从大到小排序的，还需要再翻转一下数组，没有大顶堆的效率高。

我们来分析一下上述代码的时间复杂度，假设 nums 的元素个数为 
N
N：

第一步建堆的过程中，swim 方法的时间复杂度是 
O
(
log
⁡
N
)
O(logN)，算法对每个元素调用一次 swim 方法，所以总时间复杂度是 
O
(
N
log
⁡
N
)
O(NlogN)。
第二步排序的过程中，每次 sink 方法的时间复杂度是 
O
(
log
⁡
N
)
O(logN)，算法对每个元素调用一次 sink 方法，所以总时间复杂度是 
O
(
N
log
⁡
N
)
O(NlogN)。
综上，整个堆排序的时间复杂度是 
2
N
log
⁡
N
2NlogN，用 Big O 表示就是 
O
(
N
log
⁡
N
)
O(NlogN)。与 
快速排序、
归并排序 是一个级别的排序算法。

上述算法直接操作原始数组，没有使用额外的辅助空间，所以空间复杂度是 
O
(
1
)
O(1)。
想要找到优化空间，需要利用二叉堆的一个性质：对于一个二叉堆来说，其左右子堆（子树）也是一个二叉堆。

就好比一棵二叉树的根节点，它的左右子树也是一棵二叉树。

如果你给我一个二叉树节点和两棵二叉树，那么我可以把这个二叉树节点作为根节点，两棵二叉树作为根节点的左右子树，这样就能构建出一棵新的二叉树。

二叉堆本质上是二叉树，所以也是类似的：

如果给我两个二叉堆，和一个二叉堆节点，那么我可以把这个节点作为堆顶（根节点），两个二叉堆作为左右子堆（子树），构建出一棵新的二叉堆（二叉树），对吧？

但是有个问题，构建出的这个新二叉堆，它的左右子堆肯定都符合堆的性质，但这个新的根节点的值可能不符合堆的性质，怎么办？

简单啊，sink 方法不就是专门针对这种情况的吗？只要对根节点调用一次 sink 方法，就能让这个新的二叉堆符合堆的性质了。

这就是堆排序算法的优化思路的核心，先看代码，注意建堆的部分：


// 将输入的数组元素从小到大排序
void sort(int[] nums) {
    // 第一步，原地建堆，注意这里创建的是大顶堆
    // 从最后一个非叶子节点开始，依次下沉，合并二叉堆
    int n = nums.length;
    for (int i =  n / 2 - 1; i >= 0; i--) {
        maxHeapSink(nums, i, n);
    }

    // 合并完成，现在整个数组已经是一个大顶堆

    // 第二步，排序，和刚才的代码一样
    int heapSize = n;
    while (heapSize > 0) {
        // 从堆顶删除元素，放到堆的后面
        swap(nums, 0, heapSize - 1);
        heapSize--;
        // 恢复堆的性质
        maxHeapSink(nums, 0, heapSize);
        // 现在 nums[0..heapSize) 是一个大顶堆，nums[heapSize..) 是有序元素
    }
}

每个单独的叶子节点都是符合堆的性质的，所以上述代码从最后一个非叶子节点开始，依次调用 maxHeapSink 方法，合并所有的子堆，最终整个数组就是一个大顶堆了。

n / 2 - 1 是最后一个非叶子节点的索引，这个值的运算也比较精妙，需要你熟练掌握 
完全二叉树的性质，我计划专门开一个章节把各种二叉树的性质及推导进行总结，所以这里先不展开，你有兴趣的话可以先自己思考一下。

显然，这个优化后的堆排序算法在建堆时效率更高，因为只需要对一半的元素调用 sink 方法，总的操作次数大概是 
1
/
2
∗
N
log
⁡
N
1/2∗NlogN。虽然用 Big O 表示法还是 
O
(
N
log
⁡
N
)
O(NlogN)，但实际执行的操作次数肯定会比对每个元素调用 swim 方法要少。
堆排序的稳定性
堆排序是一种不稳定的排序算法，因为二叉堆本质上是把数组结构抽象成了二叉树结构，在二叉树逻辑结构上的元素交换操作映射回数组上，无法顾及相同元素的相对位置



全新的排序原理 计数排序 
一句话总结 统计每种元素出现的次数 进而推算出每个元素在排序后 数组中的索引位置 最终完成排序 

计数排序的时间和空间复杂度都是0（n+max-min）

通用的计数排序 
计数排序需要把数组中的元素作为count数组的索引才能计数 
1。是不是只有当nums数组中的元素都是非负整数的时候才能计数排序 包含负数的时候如何排序 对自定义的类型如何排序 
2。根据计数排序的原理 我们仅仅关心一个元素出现了多少次 而并不关心相同元素的相对位置 那么看起来计数排序是一个不稳定排序 
3.因为计数排序需要将元素的值作为count数组的索引 那么如果数组中的最大元素的值很大时候 会不会导致count数组太大 空间复杂度较高 

1.处理负数和自定义类型 
最简单的计数排序场景就是待排序数组仅包含非负整数 最好这些非负整数还是从0开始的 但是我们可以通过简单映射技巧来处理负数和自定义类型 

比如 nums[-3,4,-1,2,1] 我们发现最小元素是-3 那么就不要直接把nums【i】 最为count数组的索引 而是要把 nums[i]+3作为 索引 经过f【i】 = nums[i]+3,这个映射函数索引就不包含复述了 

对于自定义类型 只需要找到一个映射类型 可以把对象映射到一个整数就可以了 其实 hash函数也是一个映射规则 但是hash函数的特点和计数排序的映射函数的特点是不一样的 

hash函数的关键指标是生成的hash值要尽量随机，而计数排序的映射函数的关键指标是不能丧失原数据的大小关系 

代码写到最后会发现问题，因为我们使用 indexFn 函数将原数组中的元素映射到了 0, 1, 2, ..., 等非负整数，但是在填充原数组进行排序时，我们必须知道 indexFn 的逆函数，才能还原出原始元素的值。

难道说需要给 sort 函数再加一个参数，传入 indexFn 的逆函数吗？不是不可以，只是还有更好的办法。


累加count数组避免使用逆函数

上面写不下去的根本原因是因为我们不知道原数组的元素排序后的索引位置 

我们通过一个小技巧 不适用逆函数也可以知道原数组的元素排序后的位置 那就是累加count数组 

count数组里面本来存储的是indexFn（nums[i]） 出现的次数 通过累加count数组 得到的是indexFn（nums[i]）在排序后的数组中的结束位置

假设nums =[2,3,1,0,2,2,3,0]都是从零开始的非负整数 所以可以忽略indexFn函数 直接用nums[i]作为count数组的索引 count = 【2,1,3,2】

0 1 2 3分别由 2 1 3 2
累加数组 count = [2,3,6,8]
count[0] = 2 说明 nums 排序后，索引区间 [0, 2) 都是元素 0；

count[1] = 3 说明 nums 排序后，索引区间 [2, 3) 都是元素 1；

count[2] = 6 说明 nums 排序后，索引区间 [3, 6) 都是元素 2；

count[3] = 8 说明 nums 排序后，索引区间 [6, 8) 都是元素 3。


void sort(int[] nums,Function<Integer,Integer> indexFn){
        int max = 0;
        //找到最大索引
        for(int num:nums){
            int index = indexFn.apply(num);
            max = Math.max(max,index)
            
        }
        //按照最大索引值决定count数组的大小
        //统计每个元素出现的次数
        int [] count = new int[max+1];
        for（int num:nums）{
            int index = indexFn.apply(num);
            count[index]++;
        }
        for(int i =1 ;i<count.length;i++){
            count[i]+=count[i-1];
        }
        //根据每个元素排序后的索引位置 完成排序 
        //这里注意从后往前遍历是为了保证排序的稳定性 
      int sorted [] = new int [nums.length];
       for(int i = nums.length;i>=0;i--){
         int index = indexFn.apply(nums[i]);
         sorted[count[index]-1] = nums[i]; 
         count[index]--;
     }
        for(int i = 0; i<nums.length;i++){
            nums[i] = sorted[i];
        }

}

倒序遍历保证排序的稳定性

因为累加 count 数组后，其中存储的是排序后元素的末尾索引，所以 sorted[count[index] - 1] = nums[i]; 也是从末尾开始向前填充的。

如果倒序遍历 nums 数组，就能保证排序的稳定性，即相同元素的相对顺序不会改变。

void sort(int[] nums) {
    // 找到最大和最小元素
    // 计算索引偏移量和 count 数组大小
    int min = Integer.MAX_VALUE, max = Integer.MIN_VALUE;
    for (int num : nums) {
        min = Math.min(min, num);
        max = Math.max(max, num);
    }

    // 根据最大值和最小值，将元素映射到从 0 开始的索引值
    int offset = -min;
    int[] count = new int[max - min + 1];

    // 统计每个元素出现的次数
    for (int num : nums) {
        count[num + offset]++;
    }

    // 累加 count 数组，得到的是 nums[i] 在排序后的数组中的结束位置
    for (int i = 1; i < count.length; i++) {
        count[i] += count[i - 1];
    }

    // 根据每个元素排序后的索引位置，完成排序
    // 这里注意，我们从后往前遍历 nums，是为了保证排序的稳定性
    int[] sorted = new int[nums.length];
    for (int i = nums.length - 1; i >= 0; i--) {
        sorted[count[nums[i] + offset] - 1] = nums[i];
        count[nums[i] + offset]--;
    }

    // 把排序结果复制回原数组
    for (int i = 0; i < nums.length; i++) {
        nums[i] = sorted[i];
    }
}

// 用法示例
int[] nums = {2, 3, 1, 0, 2, 2, -4, -1, 3, 0};
sort(nums);
这就是一个针对 int[] 数组的通用计数排序算法了，可以处理包含负数的情况。

空间复杂度
现在回答前面提出的第二个问题，如果数组中的元素的值很大时，会不会导致 count 数组太大，空间复杂度过高？

其实根据上面的代码逻辑很容分析出来，count 数组的大小是 max - min + 1，和数组元素的绝对大小无关，只和 max - min 的值，即元素的大小范围有关。

计数排序不是原地排序算法。首先它需要 count 数组辅助，消耗 
O
(
m
a
x
−
m
i
n
)
O(max−min) 的空间复杂度，另外它不能直接把排序结果写到 nums 数组中，还需要一个 sorted 数组存储排序结果，消耗 
O
(
n
)
O(n) 的空间复杂度。

综上，计数排序的空间复杂度是 
O
(
m
a
x
−
m
i
n
+
n
)
O(max−min+n)，其中 
n
n 是待排序数组的长度，
m
a
x
−
m
i
n
max−min 是待排序数组的元素范围。

根据选择排序的这个特点，当待排序数组中的极值范围跨度过大时，使用计数排序的空间复杂度会比较高，并不是明智的选择。

代码中有几个单层 for 循环，分别遍历 nums 数组和 count 数组，所以总的时间复杂度是 
O
(
n
+
m
a
x
−
m
i
n
)
O(n+max−min)，其中 
n
n 是待排序数组长度，
m
a
x
−
m
i
n
max−min 是待排序数组的元素范围。

计数排序是一个线性时间复杂度的排序算法，适用于元素范围不大的场景。你可以把上面给出的计数排序算法应用到力扣第 912 题「排序数组」上，
可以看到它的性能非常高，也没有出现内存超限的错误，应该可以推断力扣的测试用例中元素范围没有很大。
因此可知，哈希表不能替代 count 数组，因为哈希表的键并不能像数组索引这样自带有序性，所以无法完成计数排序。

非比较排序这个名词，从字面上理解，即代码中不包含 if (nums[i] > nums[j]) 这样的比较逻辑的排序算法。

之所以能不使用比较逻辑，本质在于将原数据映射到一个自带有序性的参考系中（比如数组索引），然后借助这个参考系推导出排序后的结果。

反之，如果待排序的数据不能找到这样一个映射和参考系，则无法使用非比较排序算法。

非比较排序的效率一般都比通用的比较排序要高。比如 
快速排序、
归并排序 这种通用排序算法，时间复杂度最快也就是 
O
(
n
log
⁡
n
)
O(nlogn) 了，而计数排序以及后面介绍到的其他非比较排序算法，在特定场景下的时间复杂度是线性的，性能会显著高于通用排序算法。

桶排序 

一句话总结 
桶排序算法的核心思想分三步 
1.将待排序数组中的元素使用映射函数分配到若干个桶中 
2.对每个桶中的元素进行排序 
3.最后将这些排好序的桶进行合并 得到排序结果 

桶排序算法可能并不常见，但我个人感觉它的思想非常有意思，因为你可以在它的算法思想中同时看到前面讲的 
归并排序 和 
计数排序 的影子

桶排序的关键点 

1.如何将待排序元素分配到桶中 需要决定桶的数量 并提供一个映射函数
2.如何对每个桶中的元素进行排序 理论上可以使用任意排序算法 或者模拟归并排序的思路 对每个桶递归地运行桶排序 
3.如何将排好序的桶合并起来？后面的章节会讲 
合并多个有序链表/数组 的通用算法，但那个算法会用到 
二叉堆结构，且复杂度为 
O
(
n
∗
l
o
g
k
)
O(n∗logk)，这里显然不适用：

于这三个问题，我想首先探讨其中第二个问题。不知道你有没有想过，为什么要把待排序数组分成若干个桶，然后再对每个桶进行排序？这样排序，和直接对整个待排序数组排序相比，真的有区别吗？

答案是，如果暂时不考虑合并有序桶的算法复杂度，那么分开排序当然要比整体排序效率高。
以此观之，如果桶排序将待排序元素分配到尽可能多的桶中（
k
k 尽可能大），即每个桶至多只有一个元素时，桶排序就转化成了 
计数排序，其复杂度也将降低到 
O
(
n
)
O(n)。

即便不能做到每个桶只有一个元素，只要 
k
>
1
k>1，桶排序的时间复杂度也会小于 
O
(
n
2
)
O(n 
2
 )，
k
k 越大，时间复杂度越接近 
O
(
n
)
O(n)。

反过来，如果取最小值 
k
=
1
k=1，那桶排序就完全退化成了选择排序，时间复杂度是 
O
(
n
2
)
O(n 
2
 )。

桶排序地实现 ：将元素分配到 k 个桶中
根据前面的分析，桶的数量 
k
k 会影响桶排序的时间复杂度，所以我们可以把桶的数量 
k
k 作为一个参数传入桶排序函数中。

void bucketSort(int[] nums, int k) {}
如何将待排序元素分配到 
k
k 个桶中呢？

你可能会说，之前的文章 
环形数组技巧、
哈希表原理 都遇到过类似的问题，把无限大的整数映射到有限的索引区间中，用的都是求模（余数）的技巧呀。

现在有 
n
n 个待排序元素，想分配到 
k
k 个桶中，直接求模不就行了？

for (int i = 0; i < nums.length; i++) {
    int bucketIndex = nums[i] % k;
    // 将 num 分配到第 bucketIndex 个桶中
}
实际上这样不行。

不要忘了前面的分析，你这里选择的映射函数，直接决定了合并有序桶的时间复杂。如果你使用求模这种方式进行映射，那么合并有序桶的时间复杂度就会超过 
O
(
n
)
O(n)。

为什么呢？我举个简单的例子你就明白了。假设现在待排序数组 nums 中有 0~99 这一百个数字，乱序排列，现在要把它们分配到 
k
=
10
k=10 个桶中，给你下面两种分配方法：

第一种，就是求模的方式。nums[i] % 10 = 0 的元素都分配到第一个桶中，nums[i] % 10 = 1 的元素都分配到第二个桶中，以此类推。

第二种，用除法（向下取整）。nums[i] / 10 = 0 的元素都分配到第一个桶中，nums[i] / 10 = 1 的元素都分配到第二个桶中，以此类推。

请你仔细参究，到底这两种方法有没有优劣之分？

答案是第二种用除法的方式更好。

对于第一种求模的方式，第一个桶排序好之后是 0, 10, 20, ...，第二个桶排序好之后是 1, 11, 21, ...，第三个桶排序好之后是 2, 12, 22, 32, ...，以此类推。

最后你只能用 
合并多个有序链表/数组 的通用算法，借助二叉堆来合并这些有序数组，时间复杂度是 
O
(
n
∗
l
o
g
k
)
O(n∗logk)。

再看第二种除法的方式，第一个桶排序好之后是 0, 1, 2, ...，第二个桶排序好之后是 10, 11, 12, ...，第三个桶排序好之后是 20, 21, 22, ...，以此类推。

这样的话，你只需要把这十个有序数组依次连接，就能得到一个有序数组，时间复杂度是 
O
(
n
)
O(n)。

综上，求模的方法不可行，我们需要用除法向下取整的方式来将元素分配到桶中。

那么除法中的除数如何确定呢？首先还是要使用 
计数排序 中的技巧，将数组中的元素转换为从 0 开始的非负整数，然后根据桶的个数 
k
k 就能推导出除数了。

具体看代码吧，下面将分别给出使用插入排序和递归桶排序的代码实现。


使用插入排序地桶排序 

下面地insert函数是直接从插入排序中赋值过来的 可以主要理解一下 bucketSort函数地实现 

//
void bucketSorted(int[] nums  , int bucketCount){
        int min = Integer.MAX_VALUE,max = Integer.MIN_VALUE;
        for(int num:nums){
            min = Math.min(min,num);
            max = Math.max(max,num);
        }
        int offset = -min;
        int bucketSize = (max - min)/bucketCount+1;
      //初始化桶 
      ArrayList<Integer>[] buckets = new ArrayList[bucketCount];
        for(int i = 0; i < bucketCount;i++){
            buckets[i] = new ArrayList<>();
        }
      //将元素分配到桶中 
      for(int num:nums){
        //除法向下取整地方式计算桶的索引
        int index = (num + offset)/bucketSize;
        buckets[index].add(num);
      }
      for(int i = 0;i< bucketCount;i++){
            insertSort(buckets[i]);
      }
         //合并有序桶 
      int index = 0;
      for (int i = 0 ; i<bucketCount;i++){
            for(int num:buckets[i]){
            nums[index++] = num;
            }
      }
}

// 插入排序算法，详见前文「插入排序」
void insertSort(ArrayList<Integer> nums) {
    int sortedIndex = 0;
    while (sortedIndex < nums.size()) {
        for (int i = sortedIndex; i > 0; i--) {
            if (nums.get(i) < nums.get(i - 1)) {
                int tmp = nums.get(i);
                nums.set(i, nums.get(i - 1));
                nums.set(i - 1, tmp);
            } else {
                break;
            }
        }
        sortedIndex++;
    }
}


// 使用递归的桶排序算法
void bucketSort(ArrayList<Integer> nums, int bucketCount) {
    // 判断是否所有元素都已经有序
    boolean sorted = true;
    for (int i = 1; i < nums.size(); i++) {
        if (nums.get(i) < nums.get(i - 1)) {
            sorted = false;
            break;
        }
    }
    if (sorted) {
        // 所有元素都已经有序，结束递归
        return;
    }
    // 找到最大和最小元素
    int min = Integer.MAX_VALUE, max = Integer.MIN_VALUE;
    for (int num : nums) {
        min = Math.min(min, num);
        max = Math.max(max, num);
    }

    int offset = -min;

    // 计算理论上每个桶需要装的元素个数
    int bucketSize = (max - min) / bucketCount + 1;

    // 初始化桶
    ArrayList<Integer>[] buckets = new ArrayList[bucketCount];
    for (int i = 0; i < bucketCount; i++) {
        buckets[i] = new ArrayList<>();
    }

    // 将元素分配到桶中
    for (int num : nums) {
        int index = (num + offset) / bucketSize;
        buckets[index].add(num);
    }

    // 对每个桶中的元素进行排序
    for (int i = 0; i < bucketCount; i++) {
        bucketSort(buckets[i], bucketCount);
    }

    // 合并有序桶
    int index = 0;
    for (int i = 0; i < bucketCount; i++) {
        for (int num : buckets[i]) {
            nums.set(index++, num);
        }
    }
}

桶排序的稳定性主要取决于对每个桶的排序算法，上面给出的两种实现都是稳定排序。

首先，分配元素到 
k
k 个桶的过程中，我们是按顺序遍历 nums 数组的，所有相同元素必然会被分配到同一个桶中，且在桶中的相对顺序不会改变。

最后一步合并多个桶的过程中，我们是按顺序遍历桶中的元素，所以排序稳定性主要取决于对每个桶的排序算法。

如果对每个桶中的元素使用插入排序，因为插入排序是稳定排序，所以排序过程中相同元素的相对顺序也不会改变。因此整个桶排序算法是稳定的。

如果对当前桶递归地使用桶排序，那么当前桶的元素分配到新的桶中时，相同元素的相对顺序也不会改变，以此类推，最终的排序结果也没有改变相同元素的相对位置，所以排序结果也是稳定的。




基数排序 
Radix Sort

基数排序是计数排序算法的扩展 它的主要思路是对待排序元素的每一位依次进行计数排序 由于计数排序是稳定的 所以对每一位完成计数排序后 所以元素就完成了排序 
比如十进制数的基数就是 10，二进制数的基数就是 2。看这个名字就知道这个排序算法肯定和数字的进制有关，进而可以推断，这个算法不是通用排序算法，待排序数据必须是整数，或者能够通过某种规则转化成整数，才能使用基数排序。

我发现网上的很多资料会把基数排序和桶排序放在一起，认为基数排序是桶排序的应用。

但我不认同这种看法，我认为基数排序是计数排序的扩展，可以用来解决计数排序空间复杂度过高的问题，和桶排序关系不大。
基数排序的原理
基数排序的原理很简单，比方说输入的数组都是三位数 nums = [329, 457, 839, 439, 720, 355, 350]，我们先按照个位数排序，然后按照十位数排序，然后按照百位数排序，最终就完成了整个数组的排序。

这里面的关键在于，对每一位的排序都必须是稳定排序，否则最终结果就不对了。

1、为什么对每一位必须使用稳定排序？

2、使用什么稳定排序比较好，为什么？

3、如果待排序数组中的数字不全是三位数，怎么办？有负数怎么办？

4、必须按照从个位数到高位数的顺序进行排序吗？是否可以反过来，从高位数到个位数进行排序？

最好的选择是 
计数排序。

因为计数排序的时空复杂度是 
O
(
n
+
m
a
x
−
m
i
n
)
O(n+max−min)，主要取决于待排序元素的范围，而对于基数排序的场景，十进制数的每一位都是 0-9，所以计数排序的时间空间复杂度都是线性的 
O
(
n
+
10
)
=
O
(
n
)
O(n+10)=O(n)，所以计数排序是最好的选择。
位数不同怎么办
如果待排序数组中的数字的位数不同，可以在逻辑上把所有数字都补齐成相同的位数，位数不足则在前面补 0。

比如 [1, 10, 100, 1000]，我们可以视为 [0001, 0010, 0100, 1000]。算法代码可以轻松做到这一点。

有负数怎么办
这个问题有多种解决方法，比如把正数和负数分开排序，最后再合并。

不过我觉得最简单的方法是模仿 
计数排序、
桶排序 的处理方式，给所有数字都加上一个偏移量，使得所有数字都是非负数，排序完成后再减去这个偏移量即可。

如果按照从高位到低位的顺序进行排序，最后对个位数排序，会认为 90 比 18 小，这显然是不对的。


基数排序分为从高位到低位（Most Significant Digit first，简称 MSD）和从低位到高位（Least Significant Digit first，简称 LSD）两种。

上面的整数排序算法使用的就是 LSD，MSD 的主要应用场景是字典序排序，其排序算法需要用到递归，和 LSD 有较大差异。


LSD 代码实现
假设有一个正整数 num，从右往左数（LSD），想要获取第 k 位数字（k 从 0 开始），可以使用 
(
n
u
m
/
10
k
)
%
10
(num/10 
k
 )%10 这个公式。

即使 num 的总位数小于 k，则 
(
n
u
m
/
10
k
)
%
10
=
0
(num/10 
k
 )%10=0，也是正确的。

因此，我们可以写出 LSD 基数排序代码：
void radixSortLSD(int[] nums){
        int min = Integer.MAX_VALUE;
        for(int num : nums){
            min = Math.min(min,num);
        }
        int offset = -min;
        for(int i = 0; i < nums.length;i++){
            nums[i] += offset;
        }
        int max = Integer.MIN_VALUE;
        for(int num:nums){
            max = Math.max(max,num);
        }
        int maxLen = 0;
        while(max > 0){
            max/=10;
            maxLen++;
        }
        for(int k = 0; k<=maxLen;k++){
            countSort(nums,k);
        }
}
void countSort(int[] nums,int k ){
        int [] count = new int [10];
        for(int num:nums){
            int digit = (num/(int)Math.pow(10,k))%10;
            count[digit]++;
        }
        for(int i = 1; i <count.length;i++){
            count[i]+ = count[i-1];
        }
        int[] sorted = new int[nums.length];
        for(int i = nums.length-1;i>=0;i--){
            int digit = (nums[i]/(int)Math.pow(10,k))%10;
            sorted[(count[digit]-1)] = nums[i];
            count[digit]--;
        }
        for(int i = 0;i<nums.length;i++){
            nums[i] = sorted[i];
        }
}

时空复杂度及稳定性
对于 LSD 基数排序，由于对每一位的排序都是稳定的，所以最终的排序结果也是稳定的。

假设待排序数组长度为 
n
n，最大元素的位数为 
m
m，LSD 计数排序本质上就是执行了 
m
m 次计数排序。

前文分析过，计数排序的时空复杂度都是 
O
(
n
+
m
a
x
−
m
i
n
)
O(n+max−min)，在十进制整数的基数排序的场景中，
m
a
x
−
m
i
n
max−min 的值是常数 10，可以忽略，所以每次计数排序的时空复杂度都是 
O
(
n
)
O(n)。

因此，LSD 基数排序的时间复杂度是 
O
(
m
n
)
O(mn)，空间复杂度是 
O
(
n
)
O(n)
